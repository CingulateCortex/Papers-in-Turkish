#Big Data ve Siber Guvenlik

Tarih boyunca bilgi en onemli varlik olmustur. Nasil avlanmasini bilenler hayatta kalmis, dusmani hakkinda istihbarat edinebilmisler hakimiyet kurmus, sahip olunan bilginin yanlis ellere gecmemesi adina bilgi gizleme yontemleri olusturulmus, yine ele gecirilme olasiligina karsin, bilginin butun ve gizli halde ulastirilmasi icin farkli teknikler gelistirilmistir. Bilgi sayesinde urunler gelistirilmis, gelistirilen urunlerden ekonomik kazanc elde edilmis, savunma sanayi gelismis, bilim ilerlemistir. Felsefe dahi bilgi kavraminin sorgulanmasi ile baslamistir.

Toplumlar, kendilerine ait sosyal bilgi ve sonucunda olusan algi ile bir arada kalabilecek dinamiklerini olusturmus ve hayatlarini devam ettirmislerdir.

Bilgi her daim iyi olmamistir. Dunya donuyor diyenlerin kafalarinin ucuruldugu donemler de gormustur. Yahut Pisagorcular gibi diri diri yakilanlar…

Bu noktada veri ve bilgi arasindaki farki iyi anlamak gerekir.

Esasinda cogu zaman verinin bir anlam kazanip bilgi haline gelmesi duruma bagli olarak gorecelidir. Soz gelimi bir olay karsisinda takinacagi tavri belirlemek aslinda beyindeki kocaman veri yigini arasinda ilgili olanlari secmek veriyi anlamlandirmaktir. Bir olay karsisinda anlamlandirilip bilgiye donusturulen bir verinin baska bir olay karisinda anlamli bir bilgi olma zorunlulugu yoktur.

Internet oncesinde, bilgiye erisim imkanlari kisitliydi. Bilgi’nin kendisi aslinda belirli bir guruhun tekelindeydi. Internet ile birlikte aslinda daha sosyalist bir yapi olustu. Once bilgiye ozgurce erisim, sonrasinda bilginin saklandigi yerden cikarilip herkese acik hale getirilmesi uzerine yogunlasildi.

Olayin civisi esasinda, icerigin dolayisi ile datanin kullanicilar tarafindan girilmesi ile birlikte cikti. Verinin kullanici tarafindan olusturulmasi modeli, siber dunyadaki veri artisi ivmesini cok guclendirdi. Dunya nufusunun yaklasik yarisinin internet erisimi oldugunu dusundugumuzde, olusturulan icerigin devasa boyutlari sasirtici. Walmart her saat 2,5 petabytes musteri trafigi topluyor. Twitter da her gun 250 milyon tweet atiliyor. Asil sasirtici olan ise, aslinda su an siber dunyada var olan verinin %90 ninin aslinda son 3 yil icerisinde uretilmis olmasi. Her gun 2,5 zettabyt veri bu kullanicilar tarafindan yaratilmakta.

Baslarda buyuk bir luks olan bilgiye erisimin siber dunyada kolayligi, icerigin kullanici tarafina tamamen transferi ile birlikte veri coplugu haline aldi. Coplukten kastim anlamsiz bir veri yigini degil elbette, ancak herhangi bir veriyi bir olay karsisinda anlamlilastirmak, veriler arasinda korelasyon, analoji kurarak anlamli bilgiler elde edebilmenin her gecen gun zorlasmasi asil kastettigim.

Bu acidan dusundugumuzde, gerek sirketlerin kendi ihtiyaclari bakimindan, gerek ulusal guvenlik cercevesinde istihbari faaliyetler acisindan, yahut kurumlar, birimler perspektifinde siber alan hakimiyeti guvenligi bakimindan, bu buyuk veri yigininin anlamlandirilmasi ve ihtiyac duyulan bilginin erisimi, cogu durumda geleneksel bilgi isleme yontemleri ile gerceklenemeyecek noktaya erismistir.

Ister kurumsal dunyanin bir bireyi olun, ister kendi girisiminiz icin pazar analizi yapin, isterseniz devlet olarak demografik calismalar yapin, gunun sonunda varacaginiz nokta, anlamlandirilmayi bekleyen koca bir veri yiginindan baska bir sey degildir.

Büyük veri’yi anlamak için onun oluşumundaki beş bileşeni incelemek faydalı olacaktır.

Bunlar; Variety, Velocity, Volume, Verification ve Value olarak 5V şeklinde adlandırılabilir. Tamam durust olmak gerekirse, bu tarz teorik isimlendirmelerden haz etmiyorum. Kim ne derse desin, bu anlamlandirma surecinde sezginin de payinin yuksek oldugunu dusunuyorum. Cunku, genel anlamda basit veri anlamlandirma haricinde, herhangi bir verinin ozel olarak anlamlandirilmasi, yasanan durum dogrultusunda gorecelidir. Yani bir durumdaki verinin anlamlandirilmasi icin kurulan korelasyonlar, bulunan desenler vs baska bir durumla ortusmeyebilir. Bu da sezgi ve duruma yonelik know-how ihtiyacinin aslinda yukaridaki teorik parametreler bir yana, cok daha kritik oldugunu gostermek icin yeterlidir. Yine de, bir miktar daha detaya inmeden yukaridaki parametreleri tanimakta fayda var.

Variety yani cesitlilik: Bu gun baktigimizda, verilerin cok buyuk bir kismi cok farkli platformlar icin cok farkli yapilarda uretiliyor. Esasinda, sosyoljik acidan siber dunyadaki aktiviteleri ele aldigimizda, ayni verinin farkli platformlar icin farkli yapilarda tekrar uretildigini dahi gorebiliriz. Esasinda entegrasyon surecleri hizla gelisse de, insanlarin sosyal dunyada cihazlarina bolunduklerini soylemek yanlis olmaz. Tabletler, telefonlar, bilgisayarlar vs. Tam anlami ile merkezi bir yapi kurulmus degil bireyin sosyal yasantisini siber dunyada surdurmesi acisindan…

Tum bunlar dusunuldugunde, veri cesitliligini aciklamak adina cok genel olarak uc kategoriden bahsedebiliriz. Insan-Insan, Insan-Makine ve Makine-Makine arasinda bir veri akisi devam etmektedir. Bu uc kategori ile aslinda, sosyal komuniteler, aglar, saglik, alisveris, arsiv, tv, gps, sensor, banka ve daha akliniza gelebilecek tum veri transferlerini kapsamis oluruz.

Cesitlilik disinda onemli parametrelerden biri de Velocity yani surat ya da hiz’dir. Kisisel olarak ben bu parametre icin hizin turevi olan ivme’nin daha kritik oldugunu dusunmekteyim. Gozunuzde canlandirmaniz acisindan zombi filmlerini dusunebilirsiniz. Burada iki farkli ek parametreden soz etmek mumkun. Herhangi bir toplulukta zombi virusunun yayilma hizi onemli. Ancak yayilma hizi tek basina yeterli olmaz zira temas etme sikligi yahut sansi yok sayilmistir. Buna ek olarak, zombi tarafindan isirilan bir kisinin, zombiye donusme hizi da oldukca onemlidir. Cok kabaca bunu turev gibi dusunebilirsiniz.

Ayni ornekten yola cikarak, isirilip zombiye donusen insanlarin hacmi (volume) anlamlandirma ve problem cozumu surecinde onemli bir ana parametredir. Virusun yayilmasi yavaslatilmasina yahut durdurulmasina ragmen, hali hazirda donusmus insanlarin nasil bir isleme tabi tutulacaginin kararinda, hastalik hacmi onemli yer tutar.

Ayni kaotik ornekten devam ediyoruz. Bu zombi karmasasi icinde kimin zombi olduguna teshis koymak zor olmasa da, dogru teshisin konulup dogru kanallardan ilerlemesi yine kritiktir. Buradaki dogruluk ayni zamanda surecin kendi guvenligini de kapsamaktadir elbette. Donusmemis insanlarin veri yigini icinde olmasini istemeyiz. Dikkat! gereksiz demiyorum donusmemis diyorum zira belki dunyanin ihtiyaci olan boyle bir donusumdur de henuz biz o bilissel duzeye erisememisizdir :) Buradaki kinayeyi anladiginizi ve bu espiriye guldugunuzu varsayiyorum :) Dolayisi ile dorduncu kritik parametremiz Verification yani dogrulamadir.

Son olarak verinin degerinden (value) bahsetmek gerekir ki bu da aslinda felsefi acidan yukarida yaptigim espiriye pas atiyor. Gerceklestirilen anlamlandirma surecinden sonra elde edilen veri aslinda bir bilgi halini almali yani kurum icin bir deger ifade etmeli. Burada deger kavrami da sezgi ve mantik suzgecine ihtiyac duyar. Esasinda degerli bir verinin ki bilgi diyebiliriz buna, karar asamalarinizda anlik etkisi olmalidir. Ek olarak bilgiden bilgi turetmek bir sonraki asamayi kapsamali. Yani bir kadinin bir online alisveris sitesinde, surekli hamile kiyafetlerine istek yapmasi, size kadincagizin hamile olma ihtimalini hesaplatabilmeli. Bir baskasinin, spor ayakkabi yaninda, bir short ve bir tshirt almasi, bir dakka bu adam kombinasyon yapiyor, muhtemelen spora basladi cikarimini yaptirabilmeli.

Son olarak bu cikarimlar yapilirken dinamik parametreler dikkatli dusunulmelidir. Ornegin alginin degisimi, ilginin degisimi kadar dinamik degildir. Daha uzun sureye daha cak maruz kalmaya ihtiyac duyar. Ilgi bir miktar daha daginik daha dinamiktir.

Big Data konusuna genel bir giris yaptiktan sonra daha ozel olarak siber guvenlik cercevesinden onemine deginebiliriz.

Cok kabaca bir giris olarak bir soru sormak istiyorum. Bir biyolojik silah gelistirmek istiyorsunuz, nasil bir bilgiye ihtiyaciniz olur ? Yahut bir ulkede 15-21 yas arasi gencler uzerinde bir algi operasyonu yapmak istiyorsunuz, nasil bir bilgiya ihtiyac duyarsiniz? Bu sorular uzerinde bir miktar dusunmenizde fayda var.

Bu cerceve icerisinde devam edersek, toplum her zaman bireylerin toplamindan daha anlamlidir. Gestalt yaklasimini duymussunuzdur. Birey olarak facebook paylasimlariniz tek basina, eger bir suikast hedefinde degilseniz bir sey ifade etmeyebilir. Ancak 15-21 yas arasindaki erkeklerin sevdigi filmlerin istatistigi onemli bir bilgidir.

Bu acidan dusundugunuzde gerek ofansif gerek defansif anlamda buyuk verinin kontrolu guvenlik acisindan da kritiktir.

Big Data siber guvenlik acisindan iki ana kategoriye ayrilabilir. Sosyal aglar ile olusan veri yigini ve buna ek olarak kurudugunuz siber alan ile dogrudan iliskili olan veri yigini…

Sosyal aglar ile olusan veri yiginina, savundugunuz kurum adina yapilan algi operasyonlarinin takibini de eklemek mumkundur. Kurumunuz hakkinda duzenlenen sistematik karalama kampanyalarinin takibi icin de bu buyuk veri yigini icerisinde anlamlandirma yapilmalidir. Desenler belirlenerek, kurum hakkindaki sosyal alginin ne yonde degistigi, hangi mudahaleler yapildigi, bu mudahalelerin yapildigi noktalar arasinda ne tarz iliskiler oldugu gibi sorularin tespiti genel algi yonetimi yahut askeri terminoloji ile psikolojik harekat acisindan onemlidir. Bu tespitlerin basit olanlarina bu gun twitter uzerinde rastlamaya basladik. Bir firma hakkindaki olumsuz bir tweetinize firma twitter hesabindan cevap almaya basladik.

Siber dunyadaki yasam geregi dogal yolla olusan bilgilerin yani sira, korudugunuz siber alana ait kendi big datanizi olusturmaniz cok daha onemlidir. Bunu tipki bir askeri birim gibi dusunerek gozumuzde canlandirmamiz mumkun. Bir olayin yahut olasiliklarin acik kaynaklardan toplanan verilerle anlamlandirilmasinin yaninda, kendi kaynaklari ile olusturduklari data yigini icerisinde anlamlandirilmasi seklinde dusunebiliriz. Bu bir olayin olma durumunun takibine ek olarak, olayin gerceklenmesi sonrasinda surecin analizini de icerir. Bu iki durumu birlestirdigimizde aslinda bir siber savastan bahsetmekten ziyade siber mucadeleden bahsetmek daha dogrudur. Cunku mucadele surece yayilir. mucadelenin gecmisi o ani ve gelecegi vardir. Bu nedenle siber dunyadaki ofansif yahut defansif hareketlerin mucadele sekline daha cok uydugunu soyleyebiliriz.

Daha spesifik olarak dusunuldugunde, merkezi log yonetimi ozellikle buyuk bir kurumda calisan biriyseniz dusundugunuzden cok daha kritiktir. Kimi kurumlar, yalnizca internet tarafindaki varliklarinin loglari uzerine yogunlasir. Oysa ki, bu olayin cok kucuk bir kismidir. Kisitli bir veridir. Soyle bir ornekle gozunuzde biraz daha canlandirabiliriz. Soz gelimi, kurumunuz calisanlarindan birine gelen zararli yazilim icerikli bir maile maruz kaldiginizi, ve calisaninizin bunu farketmedigini, bilgisayarina bu zararli yazilimi bulastirdigini dusunun. Boyle bir durumda elinizde sadece mail sunucu loglarinin olmasi yeterli bilgiyi size vermeyebilir. Kurumunuzdaki diger calisan bilgisayarlarindan, calisanlarin disariya dogru actiklari baglantilara kadar cesitlililik arzeden verilere ihtiyaciniz olur. Bu buyuk veri yigini icerisinde siz gerceklesmis olan saldirinin etki yuzeyini arastirirsiniz. Bunu bu buyuk veri yigini icerisinde korelasyon kurmadan veriyi bilgiye cevirmeden yapamazsiniz.

Bu noktada aslinda bahsettigim sezgi ve know-how kavramina geri donebiliriz. Big Data nin velocity ve variety tarafini kontrol altina alabilmek adina, daha once benzer savas sahnelerinden gecmis, yasak elmayi yemis, bogulma tehlikesi atlatmis, artik adina ne derseniz diyin, kaderin sillesini yemis yedirmis bir tecrubeye ihtiyac duyarsiniz. Cunku aslinda velocity ve veraity cogu zaman volume ve dolayisi ile butce tarafina etki eder. Bu noktada kahramanimiz, dogru butce ile dogru hacimde bir big data kontrolu yapar. Bu da aslinda Big Data’nin bir baska problemidir. Cogunlukla Twitter, Facebook gibi sosyal aglara kiyasla daha suurlu kocaman veri yiginlari ile bogusursunuz.

Bu noktada veri cesitliliginin kategorizasyonu onemlidir. web, proxy, mail vs loglari disinda aslinda daha temel kategoriler olusturmak gerekir. Bunlarin ne kadar dinamik oldugunu hesaba katmak gerekir. Tipki algi ve ilgi ikilisinde oldugu gibi, bir XSS saldirisi, cogu durumda fuzzing kadar dinamik olmayabilir. Yahut network tabanli saldirilarin cesitlilik hizi, uygulama katmanindaki saldirilarin cesitlilik hizindan daha dusuktur.

Ornek olayi biraz daha degistirelim;

Ornegin, loglarinizda bir active directory user’inin bilgisayarina login oldugunu goruyorsunuz. Cok normal cunku iceride domain ortami oldugundan, calisanlariniz bilgisayarlarina login olduklarinda active directory kaydi duser. Peki ya calisanlarinizin bina icerisine girerken okuttugu manyetik kart kayitlarini da log sisteminizde tutuyorsaniz ve login olan bu kullaniciya ait manyetik kart kaydi yoksa? Akliniza hemen VPN ile baglanmis olabilecegi gelebilir. Ama bunun icin de VPN kayitlarina ihtiyaciniz var oyle degil mi? Tabi bir de bu iliskiler yumagi arasinda bu korelasyonu kuracak Sherlock Holmes sezgisine :)

Biraz toparlayalim;

Big data demek icin illa binlerce gigabyte veriye ihtiyac yok. Karisinizdaki veri ihtiyaciniz olan bilgiyi size geleneksel bilgi isleme mekanizmalari tarafindan veremiyorsa, sizin icin bu big datadir. Hayatta da boyledir. Bir problem size buyuk gelebilir baskasi kolayca cozebilir :)

Big Data nerede olusuyorsa, kimin kontrolundeyse, gerek ofansif gerek defansif anlamda sizden ondedir. Bilgi guctur. Istihbarat bilimi bu nedenle vardir. Hayatta da boyledir. Bir problem cozumu icin ornek uzayinizdaki bilgi yigininin buyuklugu aslinda o problemin cevap uzayini kapsama ihtimalini artirir. O nedenle her problemde aglamayalim :)

Korelasyon ve analoji onemlidir. Hic bir sey bilmeyen birine TCP/IP anlatmaya kalktiginizda onun icin big datadir. Aslinda ogretmenlik yapmak korelasyon kurdurmaktir. Siz Networkte gezen paketleri birer araba gibi dusundururseniz yani, gercek hayattaki trafik bilgisini network yapisi icine map ederseniz, veriler anlamli hale gelir.

Istihbaratin buyuk bolumu acik kaynaklar uzerinden gerceklesir. James Bond yoktur. Masa basinda oturup veri analiz edenler vardir. Bunlar gelen bilgi yiginini istihbarata cevirir. Hayallerinizi yiktiysam bunun icin uzgunum :)

Bir kurum guvenligi dusunuldugunde, olusacak verinin, cesitliligi, dogrulugu, hizi, ivmesi, hacmi ve degeri gozden gecirilmelidir.

Data olmadan guvenlik olmaz. Bilgi olmadan eylem olmaz, istihbarat olmadan savas olmaz vs vs.

Data havuzu, savas sahalarinda deneyim kazanmis kisiler tarafindan olay odakli olusturulmalidir. Senaryolar uretilerek ne cesit verilere ne hacimde erisilmesi gerektigi belirlenmelidir. Buda dogru bir merkezi log yonetimi ile olur.

Yanlis problemli cozmeye calismak big datanin sucu degildir. problemi dogru belirlemek sorulari dogru sormak isin yarisidir. Her gun uygulamaniza yonelik bir saldiri tespit edebilirsiniz, bir sure sonra bu tespit edilen saldirilari yorumlamak da baska bir big data halini alir. Bu nedenle belki de saldiri tespitinden ziyade exploit tespitine odaklanmak daha mantiklidir. Aksi halde, sunucudan veritabanindan donen mantikli cevap olmadigi halde, siz sql injection saldirisi var diye alarm uretir gun boyu oynar durursunuz. Sonra eve gider cok yoruldum hanim dersiniz. = Goy Goy

Big Data yonetimi proje yonetimi gibidir. Yeri gelince mikro dusunursunuz, yeri gelince makro ve ikisi arasinda gecisleri yumusak yaparsiniz. Resmin buyugunu yada detayi kacirmak istemezsiniz. Seytan detayda gizlidir deseler de seytan seytandir. Detayda da gizlenir, resmin buyugunde de saklanir. Adam zaten sicak, seytansa konu cool olmak lazim :)

Degersiz bilgi yoktur. Ilgili bilgi vardir. Ilgi kurduktan sonra her bilgi degerlidir. Klasik bir fizik problemi dusunun, bir adam bir kizagi cekiyor. Iple yer arasinda 45 derecelik aci var diye gidiyor problem. 45 derece kucuk bir aci, kizak cekiyor. demek ki soguk bir yerde. dusuk aci ise boyu kisa olabilir. soguk yerde boyu kisa bir adam eskimo olabilir. eskimo ise teni beyazdir. yag orani yuksektir vs vs.

 

Dataniz ne kadar buyuk olursa olsun, sezginiz, yaraticiliginiz, korelasyonunuz o kadar guzel olsun diyerek kapatayim yazimi.